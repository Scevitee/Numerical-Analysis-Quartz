## Introduction
Another method we can use for rootfinding is known as the **fixed point problem**. In this, we are seeking to find a value that is unchanged when used as an input to a function, i.e., the input of the function matches the output for this specific value
>[!notes] Def: Fixed-point problem
>GIven a function $g$, the fixed-point problem is to find a value $p$, called a **fixed point**, such that $g(p) = p$

*How do we use this for rootfinding?*
Recall from [[4.1 The rootfinding problem|4.1]] that the rootfinding problem implies $f(r) = 0$. If we modify the fixed-point problem a bit we can get:
$$g(r) = r - f(r)$$
which simple reduces to 

$$g(r) = r$$

To actually find a fixed point of any given $g(x)$, we can use **fixed point iteration**
>[!abstract] Algorithm: fixed-point iteration
>Given a function $g$ and an intial value $x_1$, define
>$$x_{k+1} = g(x_k), \ \ \ \ \ \ k = 1, 2, ...$$

The procedure for this algorithm is as follows:
1. Start with an initial guess $x_1$
2. Apply $g$ to $x_1$, calculate $x_2 = g(x_1)$ This gives the next approximation of the fixed point
3. Iterate: Continue the process, using the output of the previous step as the input for the next
4. Repeat until convergence / until the difference between the approximations is below a predetermined tolerance level

The textbook provides a fairly verbose demo that illustrates the algorithm. It's a lot to copy so I'll just leave this [link](https://fncbook.github.io/fnc/nonlineqn/demos/fp-spiral.html)

## Series Analysis
In the textbook demo, it shows that for one choice of $x_1$, the sequence converged to a fixed point, whereas for a different choice of $x_1$, it diverged. 
So, how can we tell if a fixed-point iteration will converge?

>[!info] Observation
>Fixed-point iteration for a differentiable $g(x)$ converges to a fixed point $p$ if the intial error is sufficiently small and $|g'(p)| < 1$. The iteration diverges for all initial values if $|g'(p)| > 1$


## Linear Convergence



## Contraction Maps



## Examples